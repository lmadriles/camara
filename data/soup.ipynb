{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5cac9cb8",
   "metadata": {},
   "source": [
    "# Web scraping\n",
    "\n",
    "Este notebook é uma demonstração de como extrair dados de votação de algum evento parlamentar da Câmara dos Deputados.\n",
    "\n",
    "Você pode utulizá-lo para extrair dados das votações que seguem o mesmo padrão html da utilizada nesse exemplo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47e710ff",
   "metadata": {},
   "source": [
    "### Documentação das bibliotecas utilizadas: \n",
    "\n",
    "<a href=\"https://docs.python-requests.org/en/latest/\" title=\"Requests\">Requests</a>\n",
    "\n",
    "<a href=\"https://www.crummy.com/software/BeautifulSoup/bs4/doc/#\" title=\"BeautifulSoup\">BeautifulSoup</a>\n",
    "\n",
    "<a href=\"https://pandas.pydata.org/docs/\" title=\"Pandas\">Pandas</a>\n",
    "\n",
    "<a href=\"https://docs.python.org/3/library/re.html\" title=\"Regular Expressions\">Regular Expressions</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05e095a9",
   "metadata": {},
   "source": [
    "### Permissões:\n",
    "\n",
    "Caso use esse algoritmo para raspagem, não utilizem urls que violem o <a href=\"https://www.camara.leg.br/robots.txt\" title=\"Protocolo de Exclusão de Robôs\">Protocolo de Exclusão de Robôs</a>:\n",
    "\n",
    "- User-Agent: * \n",
    "- Disallow: /sileg/prop_lista* \n",
    "- Disallow: /internet/sileg/prop_lista* \n",
    "- Disallow: /sileg/Prop_lista* \n",
    "- Disallow: /internet/sileg/Prop_lista* \n",
    "- Disallow: /*arvore-de-apensados \n",
    "- Disallow: /proposicoesWeb/prop_arvore_tramitacoes \n",
    "- Disallow: /sileg/prop_arvore_tramitacoes \n",
    "- Disallow: /internet/deputado/Dep_Lista* \n",
    "- Disallow: /transparencia/recursos-humanos/remuneracao/*\n",
    "- Disallow: /transparencia/recursos-humanos/contratos-terceirizacao* \n",
    "- Disallow: /transparencia/recursos-humanos/funcionarios* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "248c6b1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importando as bibliotecas necessárias\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import re # expressões regulares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2e1fbd22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_html(url):\n",
    "    \"\"\"Extract the html code of the page.\n",
    "    \n",
    "    Args:\n",
    "        url (str): page's url\n",
    "\n",
    "    Returns:\n",
    "        html_str (str): html extracted\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        r = requests.get(url) \n",
    "        html_str = r.text \n",
    "    except:\n",
    "        raise HTTPException(404)\n",
    "        \n",
    "    return html_str\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d283c13",
   "metadata": {},
   "source": [
    "Abaixo temos um exemplo de um elemento da lista que contém todas as informações que precisamos por palarmentar.\n",
    "\n",
    "    <li>\n",
    "      <span class=\"nome\">Abou Anni</span>\n",
    "      <span class=\"nomePartido\">(PSL-SP)</span>\n",
    "      <span class=\"votou\">-votou<span class=\"voto sim\">Sim</span></span>\n",
    "     </li>\n",
    "\n",
    "Precisamos navegar até o elemento de cada deputado e extrair as informações relevantes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9fa11141",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_page(html_str):\n",
    "    \"\"\"Extract, assemble and returns the voting information from html in a 2D list.\n",
    "    \n",
    "    Args:\n",
    "        html_str (str): html as a string\n",
    "    \n",
    "    Returns:\n",
    "        vote_info (list): data scraped from html with shape (number of votants, number of features).\n",
    "    \n",
    "    \"\"\"\n",
    "    # crinado o objeto soup\n",
    "    soup = BeautifulSoup(html_str) \n",
    "\n",
    "    # inicializa a lista\n",
    "    vote_info = []\n",
    "    \n",
    "    # percorre o item de lista com a info:\n",
    "    for elemento in soup.find_all('span', attrs={\"class\":\"nome\"}):\n",
    "        lista = []\n",
    "        \n",
    "        lista.append(elemento.parent.contents[1].string) # nome do parlamentar\n",
    "        \n",
    "        party_state = re.search(r'\\((.*?)-(.*?)\\)',elemento.parent.contents[3].string)\n",
    "        lista.append(party_state.group(1)) # partido\n",
    "        lista.append(party_state.group(2)) # unidade federativa\n",
    "        \n",
    "        # Voto\n",
    "        if not elemento.parent.select('span.votou span'): # lista vazia não tem método .string:\n",
    "            lista.append('Sem voto') # ausência\n",
    "        else:\n",
    "            lista.append(elemento.parent.select('span.votou span')[0].string) # voto\n",
    "        \n",
    "        vote_info.append(lista)\n",
    "        \n",
    "    return vote_info\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0caa671a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_data(vote_info, csv_name='saved'):\n",
    "    \"\"\"\n",
    "    Convert 2D list into pandas DataFrame and store it into a .csv file.\n",
    "    \n",
    "    Args:\n",
    "        vote_info (list): 2D list with the information gathered\n",
    "        csv_name (str): name of the file to be created\n",
    "    \"\"\"\n",
    "    df = pd.DataFrame(vote_info, columns=['nome', 'partido', 'estado', 'voto'])\n",
    "    csv_name = csv_name + '.csv'\n",
    "    df.to_csv(csv_name, index=False)\n",
    "    return\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "62b1c4bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scraper(url, csv_name):\n",
    "    \"\"\"\n",
    "    Recieves a url, scrape the voting information and saves it into a csv file.\n",
    "    \n",
    "    Args:\n",
    "        url (str): page's url\n",
    "        csv_name (str): name of the file to be created\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    html = extract_html(url)\n",
    "    vote_info = scrape_page(html)\n",
    "    save_data(vote_info, csv_name)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "191ea265",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               nome     partido estado      voto\n",
      "0    AJ Albuquerque          PP     CE  Sem voto\n",
      "1    Abílio Santana          PL     BA  Sem voto\n",
      "2         Abou Anni         PSL     SP       Sim\n",
      "3    Acácio Favacho        PROS     AP  Sem voto\n",
      "4      Adolfo Viana        PSDB     BA  Sem voto\n",
      "..              ...         ...    ...       ...\n",
      "504       Zé Carlos          PT     MA       Não\n",
      "505         Zé Neto          PT     BA       Não\n",
      "506        Zé Silva  Solidaried     MG  Sem voto\n",
      "507        Zé Vitor          PL     MG       Sim\n",
      "508     Zeca Dirceu          PT     PR       Não\n",
      "\n",
      "[509 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    url = 'https://www.camara.leg.br/presenca-comissoes/votacao-portal?reuniao=62583&itemVotacao=9968&ordenacao=Nome'\n",
    "    scraper(url, 'pec135')\n",
    "    \n",
    "    df = pd.read_csv('pec135.csv')\n",
    "    \n",
    "    print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab6d05cc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
